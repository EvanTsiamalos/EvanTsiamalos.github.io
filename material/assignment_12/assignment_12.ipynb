{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Lab 12\n",
    "In this lab, you will conduct hypothesis tests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Sleep\n",
    "The dataset below contains the answers of students of UIUC to some questions. In this section, we are going to try to answer the following statistical question:\n",
    "\n",
    "> **Do UIUC students get significantly different sleep compared to the average American?**\n",
    "\n",
    "First, import the Dataset. \n",
    "\n",
    "The dataset is available here:\n",
    "```\n",
    "https://evantsiamalos.github.io/material/datasets/hello.csv\n",
    "```\n",
    "\n",
    "Use Python to load this dataset into a DataFrame called `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up The Test\n",
    "In 2013, [Gallup completed their latest survey on sleep](https://news.gallup.com/poll/166553/less-recommended-amount-sleep.aspx) that shows that the average amount of sleep Americans get is **6.8 hours**.  \n",
    "\n",
    "To determine whether Illinois students get significantly more or less sleep than the average American, we will treat the observations above as a **random sample** of the student population at UIUC. Then, we will conduct a **one-sample, two-sided Z-test** to answer our hypothesis. \n",
    "\n",
    "Before we begin, define our hypotheses. Remember, the average amount of sleep found in Gallup's study is **6.8** hours, and we want to determine if our random sample is **significantly different** from this average. \n",
    "\n",
    "**Write your null and alternative hypothesis using the cell below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(✏️ Edit this cell to replace this text with your answer. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1: Sample Statistics\n",
    "The first step in order to perform a hypothesis test is to find the sample mean $\\bar X$ and the sample variance $s^2$. The dataset `df` contains the ammount of sleep that students get under the column named \n",
    "\n",
    "> \"How many hours do you sleep in a day?\"\n",
    "\n",
    "Assign this column **name** to a **string variable** named `sleep_column_name` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_column_name = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using `sleep_column_name` and your `df`, find the sample average of the ammount of sleep that the students get, storing the result in the `sleep_average`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_average = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the sample **variance** of hours of sleep of the students, storing the result in the `sleep_var`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_var = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, find the **sample size**, storing the result in the **integer variable** `sample_size`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2: Finding the P-value\n",
    "We are going to perform a hypothesis test on a $0.05$-significance level\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the test statistic:\n",
    "\n",
    "$$\\frac{\\bar X - \\mu_0}{\\sqrt{\\frac{\\sigma^2}{n}}}$$\n",
    "\n",
    "with $\\mu_0 = 6.8$.\n",
    "\n",
    "Store your result in a variable called `test_statistic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic = ...\n",
    "test_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the p-value (according to your hypothesis test setup). Store your result into a variable called `p_value`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = ...\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "**What is your result? Do you reject $H_0$ or not and why?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(✏️ Edit this cell to replace this text with your answers. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python Libraries\n",
    "We had to do a significant amount of calculations by hand to find our P-value. \n",
    "\n",
    "Luckily, Python has a few **libraries** which contain functions that allow us to conduct our hypothesis tests without calculating by hand. We are going to conduct the same test, only this time, it will be done automatically by Python. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import weightstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function we will be using is `weightstats.ztest()`. Our use of this function will take **three parameters** in the following order:\n",
    "1. A `list` of sampled values\n",
    "2. The **expected value** of the null hypothesis, specified using `value=`\n",
    "3. The **alternative hypothesis** to the null value (either 'two-sided', 'larger', or 'smaller', specified using `alternative=`)\n",
    "\n",
    "To learn more about **Z-test function**, visit: https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ztest.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.3: Z-test in Python\n",
    "Using the cell below, call the `weightstats.ztest()` function to conduct our Z-test and store the results in the variable `sleep_results`.\n",
    "\n",
    "The function `weightstats.ztest()` takes **three parameters**. Calling it will look like:\n",
    "\n",
    "`weightstats.ztest(list, value=..., alternative=...) `\n",
    "\n",
    "with the parameters being\"\n",
    "1. A list of sampled values. In our case it is the column of the dataset that we are using (i.e. `df[sleep_column_name]`)\n",
    "\n",
    "2. The expected value of the null hypothesis, specified using ` value= `\n",
    "\n",
    "\n",
    "3. The alternative hypothesis to the null value (either `'two-sided'`, `'larger'`, or `'smaller'`, specified using `alternative=`\n",
    "Use the appropriate arguments for the parameters in order to conduct the test. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_results = ...\n",
    "\n",
    "### SOLUTION ###\n",
    "sleep_results = weightstats.ztest(df_hello[sleep_question], value=6.8, alternative='two-sided')\n",
    "sleep_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you print `sleep_result`, it should be a pair of **two values** in the form of $(z, p)$ where $z$ is the `z-stat` and $p$ is the `p-value`. If done correctly, the p-value should be **almost identical** to what you calculated by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: The Party\n",
    "Our knowledge of the `weightstats.ztest()` function from above lets us conduct a hypothesis test on any of our columns with ease. \n",
    "\n",
    "The column we are going to deal with in this section is \n",
    "\n",
    "> *\"In the past year, how many times have you been to the party?\"* \n",
    "\n",
    "The next question we'll answer with a Z-test is:\n",
    "> **It is assumed that the average student has been to \"the party\" $5$ times in the past year. Do UIUC students attend \"the party\" *more* than the average student?**\n",
    "\n",
    "\n",
    "\n",
    "In sections 1.2 and 1.3, we conducted a **two-sided Z-test**.\n",
    "\n",
    "Now, we will conduct a **one-sided Z-test** of significance level $0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Our Hypotheses\n",
    "**Define the null and alternative hypotheses using the cell below.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(✏️ Edit this cell to replace this text with your answers. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df` dataset contains the number of times our sample of students have been to \"the party\" under the **column** named `\"In the past year, how many times have you been to the party?\"`.\n",
    "\n",
    "To begin, assign this column name to a **string variable** named `party_question` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_question = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "There's something a little tricky about the data we have in this column. Some people haven't filled out the answer to this question, causing `NaN` (empty) values to appear. Dealing with **null values** is a **common occurence** in Data Science. We'll have to **chain** a simple **data cleaning** step.\n",
    "\n",
    "\n",
    "\n",
    "Using the `.dropna()` function, create a new variable named `party_column_clean` containing only the values from rows **without null (NaN) answers** to our `party_question`.\n",
    "\n",
    "**Hint:** Your solution should follow the syntax of `df[column].dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_column_clean = ...\n",
    "party_column_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything ready to conduct our **one-sided Z-test**. \n",
    "\n",
    "Using the cell below, call the `weightstats.ztest()` function to conduct our **one-sided Z-test**, storing the results in the variable `party_results`.\n",
    "\n",
    "Our usage of `weightstats.ztest()` takes **three parameters**. Calling it will look like:\n",
    "\n",
    "`weightstats.ztest(list, value=..., alternative=...) `\n",
    "\n",
    "Remember we are conducting a **one-sided** test to determine whether Illinois students have been to \"the party\" **more** than the **$5$ times** in the past year that the average student has been to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_results = ...\n",
    "party_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "**What is your result? Do you reject $H_0$ or not and why?**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(✏️ Edit this cell to replace this text with your answers. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Happiness and Credit Hours\n",
    "Let's do another hypothesis test! This time we are going to look at the relationship between happiness and credit hours! \n",
    "\n",
    "We are going to answer the following question:\n",
    "- **Are students who take less credit hours significantly *happier* than students who take more?**\n",
    "\n",
    "To answer, we will perform a **one-sided two-sample z-test** of significance level $0.05$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Our Hypotheses\n",
    "**Define the null and alternative hypotheses using the cell below.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(✏️ Edit this cell to replace this text with your answers. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.1: Setting Up\n",
    "We'll be using the the `weightstats.ztest()` function again to conduct our two sample z-test.\n",
    "\n",
    "To make our code **simpler and readable**, in the next cell, create two variables for future column subselection from our `df`:\n",
    "1. A **string variable** named `credits_question`, containing the **string**: \"How many credit hours are you taking?\"\n",
    "2. A **string variable** named `happiness_question`, containing the **string**:  \"From 1 to 10, how happy are you right now?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_question = ...\n",
    "happiness_question = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will need to **clean** our DataFrame before conducting these tests. Here's a list of issues we will need to take care of before doing our test:\n",
    "- Some people **did not respond** to the `credits_question`, producing `NaN` values. \n",
    "- Some people responded with **unreasonable** answers to the `credits_question` (any answer **above 25** does not make sense)\n",
    "- Some people **did not respond** to the `happiness_question`, producing `NaN` values.\n",
    "- Some people responded with **unreasonable** answers to the `happiness_question` (any answer **above 10** does not make sense because of the 1-10 scale)\n",
    "\n",
    "\n",
    "In order to fix this: \n",
    "\n",
    "- create a new dataframe called `df_1` where you only keep the two columns that we are interested in.\n",
    "\n",
    "- using `df_1` create a second dataframe called `df_clean` by :\n",
    "    - first keeping the rows of `df_1` where `credits_question` is less or equal to 25 **and** `happiness_question` is less or equal to 10 \n",
    "    - dropping the NAN values in the end (by using `.dropna()` in the end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = ...\n",
    "\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = ...\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned our columns in `df_clean`, we can continue with our test setup. \n",
    "\n",
    "In order to conduct our test, we are going to separate our data into students who have many credit hours and students who have less credit hours.\n",
    "\n",
    "Using your `credits_question` variable, create **two** new `DataFrames`: \n",
    "- `df_many_credits`, containing the rows from `df_clean` with students taking **15 or more** credit hours. \n",
    "- `df_less_credits`, containing the rows from `df_clean` with students taking **less than 15** credit hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.2: Conducting the Test\n",
    "Now we have the samples we need for our **two-sample Z-test**.\n",
    "\n",
    "Now, let's run the our Z-test. Using the cell below, call the `weightstats.ztest()` function to conduct our Z-test and store the results in the variable `happy_results`. \n",
    "\n",
    "In the `weightstats.ztest()`\n",
    "\n",
    "- the first argument is going to be the `happiness_question` column from `df_many_credits` \n",
    "\n",
    "- the first argument is going to be the `happiness_question` column from `df_less_credits` \n",
    "\n",
    "\n",
    "- The third argument is going to be `value = 0` (because we are testing if $\\mu_{many}- \\mu_{less} = 0$)\n",
    "\n",
    "- The forth argument is going to be `alternative = ...`  (choose appropriately from `'two-sided'`, `'larger'`, or `'smaller'`)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "### SOLUTION ###\n",
    "\n",
    "happy_results = weightstats.ztest(df_many_credits[happiness_question], df_less_credits[happiness_question], alternative='smaller')\n",
    "happy_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## == CHECKPOINT TEST CASES ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any errors, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check your previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "import urllib\n",
    "_j = \"https://evantsiamalos.github.io/material/assignment_12/assignment12_tester.py\"\n",
    "_ = urllib.request.urlopen(_j).read()\n",
    "exec(_)\n",
    "Tester.testCase9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "**What is your result? Do you reject $H_0$ or not and why?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(✏️ Edit this cell to replace this text with your answers. ✏️)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Download and submit the assignment on Canvas in **Assignment 12**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e4deb337457fa8947131008f75dc159c243dc668058f6d523698d9cd505a843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
